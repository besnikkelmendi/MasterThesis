# -*- coding: utf-8 -*-
"""MobilenetV2Test

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VhOUx4DgsJGEPlO5cT9YVg34wjaAc-IA
"""

import pickle
from client import densenet, mobilenet
import keras
import tensorflow as tf

import keras.backend as K
from keras.models import Model
from keras.layers import Input, Dense, Conv2D, Conv3D, DepthwiseConv2D, SeparableConv2D, Conv3DTranspose
from keras.layers import Flatten, MaxPool2D, AvgPool2D, GlobalAvgPool2D, UpSampling2D, BatchNormalization
from keras.layers import Concatenate, Add, Dropout, ReLU, Lambda, Activation, LeakyReLU, PReLU


# from IPython.display import SVG
from keras.utils.vis_utils import model_to_dot

from time import time
import numpy as np
import pandas as pd

# from google.colab import drive
# drive.mount("/content/gdrive", force_remount=True)

INPUT_SHAPE = 224, 224, 3
N_CLASSES = 5

K.clear_session()
# model = squeezenet(INPUT_SHAPE, N_CLASSES)
# model.summary()

train_df = pd.read_csv('train.csv')
# test_df = pd.read_csv('test.csv')
print(train_df.shape)
# print(test_df.shape)
train_df.head()

from PIL import Image
from tqdm import tqdm
import cv2
N = train_df.shape[0]
x_train = np.empty((N, 224, 224, 3), dtype=np.uint8)

def preprocess_image(image_path, desired_size=224):
    im = Image.open(image_path)
    # im = im.resize((desired_size, )*2, resample=Image.LANCZOS)
    
    return im

# for i, image_id in enumerate(tqdm(train_df['id_code'])):
#     img = cv2.imread(f'/content/gdrive/MyDrive/Colab/Thesis/Datasets/Small/train_images_resized/{image_id}.png')
#     img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

#     batch_images.append(img)


for i, image_id in enumerate(tqdm(train_df['id_code'])):
    x_train[i, :, :, :] = preprocess_image(
        f'train_images_resized/{image_id}.png'
    )
    
# x_train = np.array(batch_images, np.float32) / 255.0

# from tf.keras.utils import to_categorical

y = train_df['diagnosis']
y_train = tf.keras.utils.to_categorical(y, num_classes=2)

# from sklearn.model_selection import train_test_split
# # y_train = train_df[['diagnosis']]
# print(y_train.shape)
# X_train, x_val, Y_train, y_val = train_test_split(
#     x_train, y_train, 
#     test_size=0.15, 
#     random_state=42
# )
def densenet(img_shape, n_classes, f=32):
  repetitions = 6, 12, 24, 16
  
  def bn_rl_conv(x, f, k=1, s=1, p='same'):
    x = BatchNormalization()(x)
    x = ReLU()(x)
    x = Conv2D(f, k, strides=s, padding=p)(x)
    return x
  
  
  def dense_block(tensor, r):
    for _ in range(r):
      x = bn_rl_conv(tensor, 4*f)
      x = bn_rl_conv(x, f, 3)
      tensor = Concatenate()([tensor, x])
    return tensor
  
  
  def transition_block(x):
    x = bn_rl_conv(x, K.int_shape(x)[-1] // 2)
    x = AvgPool2D(2, strides=2, padding='same')(x)
    return x
  
  
  input = Input(img_shape)
  
  x = Conv2D(64, 7, strides=2, padding='same')(input)
  x = MaxPool2D(3, strides=2, padding='same')(x)
  
  for r in repetitions:
    d = dense_block(x, r)
    x = transition_block(d)
  
  x = GlobalAvgPool2D()(d)
  
  output = Dense(n_classes, activation='softmax')(x)
  
  model = Model(input, output)
  return model
  
def squeezenet(input_shape, n_classes):
  
  def fire(x, fs, fe):
    s = Conv2D(fs, 1, activation='relu')(x)
    e1 = Conv2D(fe, 1, activation='relu')(s)
    e3 = Conv2D(fe, 3, padding='same', activation='relu')(s)
    output = Concatenate()([e1, e3])
    return output
  
  
  input = Input(input_shape)
  
  x = Conv2D(96, 7, strides=2, padding='same', activation='relu')(input)
  x = MaxPool2D(3, strides=2, padding='same')(x)
  
  x = fire(x, 16, 64)
  x = fire(x, 16, 64)
  x = fire(x, 32, 128)
  x = MaxPool2D(3, strides=2, padding='same')(x)
  
  x = fire(x, 32, 128)
  x = fire(x, 48, 192)
  x = fire(x, 48, 192)
  x = fire(x, 64, 256)
  x = MaxPool2D(3, strides=2, padding='same')(x)
  
  x = fire(x, 64, 256)
  x = Conv2D(n_classes, 1)(x)
  x = GlobalAvgPool2D()(x)
  
  output = Activation('softmax')(x)
  
  model = Model(input, output)
  return model

def resnet(input_shape, n_classes):
  
  def conv_bn_rl(x, f, k=1, s=1, p='same'):
    x = Conv2D(f, k, strides=s, padding=p)(x)
    x = BatchNormalization()(x)
    x = ReLU()(x)
    return x
  
  
  def identity_block(tensor, f):
    x = conv_bn_rl(tensor, f)
    x = conv_bn_rl(x, f, 3)
    x = Conv2D(4*f, 1)(x)
    x = BatchNormalization()(x)
    
    x = Add()([x, tensor])
    output = ReLU()(x)
    return output
  
  
  def conv_block(tensor, f, s):
    x = conv_bn_rl(tensor, f)
    x = conv_bn_rl(x, f, 3, s)
    x = Conv2D(4*f, 1)(x)
    x = BatchNormalization()(x)
    
    shortcut = Conv2D(4*f, 1, strides=s)(tensor)
    shortcut = BatchNormalization()(shortcut)
    
    x = Add()([x, shortcut])
    output = ReLU()(x)
    return output
  
  
  def resnet_block(x, f, r, s=2):
    x = conv_block(x, f, s)
    for _ in range(r-1):
      x = identity_block(x, f)
    return x
    
  
  input = Input(input_shape)
  
  x = conv_bn_rl(input, 64, 7, 2)
  x = MaxPool2D(3, strides=2, padding='same')(x)
  
  x = resnet_block(x, 64, 3, 1)
  x = resnet_block(x, 128, 4)
  x = resnet_block(x, 256, 6)
  x = resnet_block(x, 512, 3)
  
  x = GlobalAvgPool2D()(x)
  
  output = Dense(n_classes, activation='softmax')(x)
  
  model = Model(input, output)
  return model


# model = tf.keras.applications.MobileNetV3Large((224, 224, 3), classes=5, weights=None)
model = resnet(INPUT_SHAPE, 2)
model.compile("adam", "categorical_crossentropy", metrics=["accuracy"])

history = model.fit(
            x_train,
            y_train,
            # batch_size = 4,
            epochs=20,
            validation_split=0.20,
            )

np.save('history-res.npy',history.history)

with open('trainHistoryDictRes', 'wb') as file_pi:
        pickle.dump(history.history, file_pi)



# model = tf.keras.applications.MobileNetV3Small((224, 224, 3), classes=5, weights=None)
# model.compile("adam", "categorical_crossentropy", metrics=["accuracy"])
# model.summary()

